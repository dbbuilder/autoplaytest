# GPT AI Provider Configuration
# Settings specific to OpenAI's GPT API

provider:
  name: "gpt"
  display_name: "OpenAI GPT-4"
  api_base_url: "https://api.openai.com/v1"
  
models:
  default: "gpt-4-turbo-preview"
  available:
    - name: "gpt-4-turbo-preview"
      max_tokens: 4096
      supports_vision: true
      cost_per_1k_input: 0.01
      cost_per_1k_output: 0.03
      
    - name: "gpt-4"
      max_tokens: 8192
      supports_vision: false
      cost_per_1k_input: 0.03
      cost_per_1k_output: 0.06
      
    - name: "gpt-3.5-turbo"
      max_tokens: 4096
      supports_vision: false
      cost_per_1k_input: 0.0005
      cost_per_1k_output: 0.0015
      
    - name: "gpt-4-vision-preview"
      max_tokens: 4096
      supports_vision: true
      cost_per_1k_input: 0.01
      cost_per_1k_output: 0.03

# Request parameters
request_params:
  temperature: 0.2
  max_tokens: 4096
  top_p: 0.95
  frequency_penalty: 0
  presence_penalty: 0
  n: 1
  
# Rate limiting
rate_limits:
  requests_per_minute: 60
  tokens_per_minute: 90000
  concurrent_requests: 10
  
# Retry configuration
retry:
  max_attempts: 3
  initial_delay: 1
  max_delay: 10
  exponential_base: 2
  
# Special features
features:
  supports_system_prompt: true
  supports_function_calling: true
  supports_vision: true
  supports_streaming: true
  max_context_window: 128000  # GPT-4 Turbo
  
# Headers
headers:
  content-type: "application/json"
  
# Error handling
error_messages:
  rate_limit: "OpenAI rate limit exceeded"
  api_error: "OpenAI API error occurred"
  timeout: "Request timed out"
  invalid_key: "Invalid OpenAI API key"
  quota_exceeded: "API quota exceeded"